{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26791970",
   "metadata": {},
   "source": [
    "# Pre-processamento dos dados\n",
    "\n",
    "O data set fornecido para este problema não vinha ainda preparado para ser alimentado aos modelos de deeplearning.\n",
    "\n",
    "Neste notebook são detalhadas todas as estratégias de preprocessamento das sequências de proteinas.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882fd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc1da8",
   "metadata": {},
   "source": [
    "## Processamento das sequências em subsequências de trimeros\n",
    "\n",
    "Esta funcão permite apartir de uma sequencia de aminoacidos gerar 3 listas de trimeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequence(seq):\n",
    "    offset0 = re.findall(r'...', seq)\n",
    "    offset1 = re.findall(r'...', seq[1:])\n",
    "    offset2 = re.findall(r'...', seq[2:])\n",
    "    return [offset0, offset1, offset2]\n",
    "\n",
    "\n",
    "def sequences2subsequences(seq):\n",
    "    return list(map(subsequence, seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd2c88",
   "metadata": {},
   "source": [
    "## Construção da representação da sequência num vector de 100 dimensões\n",
    "\n",
    "Esta função ao receber as 3 listas de subsequências e o dicionario de vetores transforma-as em um representação em que os vetores associados a cada trimero são somados num único vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2fixed_length_vec(seqs, vocabulary):\n",
    "    flat_threemers = [item for sublist in seqs for item in sublist]\n",
    "    vec = np.array([0.0] * 100)\n",
    "    for t in flat_threemers:\n",
    "        try:\n",
    "            vec = np.add(vec, vocabulary[t])\n",
    "        except:\n",
    "            vec = np.add(vec, vocabulary['<unk>'])\n",
    "    global countline\n",
    "    countline += 1\n",
    "    if countline % 10 == 0:\n",
    "        print(countline)\n",
    "    print(vec)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e7b90",
   "metadata": {},
   "source": [
    "## Construção da representação com Wordcount/Matriz de vocabulario\n",
    "\n",
    "Esta função ao receber as 3 listas de subsequências e o dicionario de vetores transforma-as em um representação em que cada posição está associada a um trimero do vocabulario e contem o vetor do mesmo multiplicado pelo número de vezes que aparece na sequência "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2wordcount_vec(seqs, vocabulary):\n",
    "    flat_threemers = [item for sublist in seqs for item in sublist]\n",
    "    wordcount = []\n",
    "    for val in range(len(vocabulary.keys())):\n",
    "        wordcount.append([0.0] * 100)\n",
    "    for t in flat_threemers:\n",
    "        try:\n",
    "            wordcount[list(vocabulary.keys()).index(t)] = np.add(wordcount[list(vocabulary.keys()).index(t)],\n",
    "                                                                 vocabulary[t])\n",
    "        except:\n",
    "            wordcount[list(vocabulary.keys()).index('<unk>')] = np.add(\n",
    "                wordcount[list(vocabulary.keys()).index('<unk>')],\n",
    "                vocabulary['<unk>'])\n",
    "    return np.array(wordcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b97276",
   "metadata": {},
   "source": [
    "## Construção da representação com Matriz e Padding\n",
    "\n",
    "Esta função ao receber as 3 listas de subsequências e o dicionario de vetores transforma-as em um representação em que cada trimero é substituido pelo vetor correspondente.\n",
    "\n",
    "Seguidamente é efectuado padding com vetores 0 de 100 dimensões até atingir a max_len - 2 de modo a obter uma representação consistente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ca15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2fixed_vec_matrix(seqs, vocabulary, maxlen):\n",
    "    flat_threemers = [item for sublist in seqs for item in sublist]\n",
    "    vec_array = []\n",
    "    for t in flat_threemers:\n",
    "        try:\n",
    "            vec_array.append(vocabulary[t])\n",
    "        except:\n",
    "            vec_array.append(vocabulary['<unk>'])\n",
    "    while len(vec_array) < maxlen-2:\n",
    "        vec_array.append(np.array([0.0] * 100))\n",
    "\n",
    "    global countline\n",
    "    countline += 1\n",
    "    if countline % 10 == 0:\n",
    "        print(countline)\n",
    "    return np.array(vec_array, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97caa13b",
   "metadata": {},
   "source": [
    "##  Tratamento do E.C Number\n",
    "\n",
    "O E.C numbér é a coluna objectivo deste dataset, no entanto este é composto 4 niveis separados por pontos esta função permite escolher o numero de niveis a considerar bem como eliminar proteinas com 2 EC numbers incompativeis ou sem classificação para o nivel pedido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b50809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_ec_number(ec_number, ecn_level):\n",
    "    if ecn_level <= 0 or ecn_level > 4:\n",
    "        raise ValueError('EC number level must be between 1-4')\n",
    "    keep = True\n",
    "    numbers = ec_number.split(';')\n",
    "    ret = numbers[0].split('.')[:ecn_level]\n",
    "    for n in numbers:\n",
    "        n = n.split('.')[:ecn_level]\n",
    "        if ret != n or '-' in n:\n",
    "            keep = False\n",
    "    if keep:\n",
    "        return ','.join(ret)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58bd206",
   "metadata": {},
   "source": [
    "## Função de pre-processamento\n",
    "\n",
    "Esta função serve basicamente para linearizar o pre-processamento dos dados permitindo ao grupo obter as diferentes representações dos dados apenas pela mundaça de argumentos.\n",
    "\n",
    "Esta função produz um Dataframe com os campos \"ec_number\" que são os labels e \"vectors\" que é a representação da sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(dataset, vocabulary, representation='matrix', maxlen=700, ecn_level=1):\n",
    "    dataset = dataset[dataset.get('sequence').notna()]  # Removing null values from sequence column\n",
    "    dataset = dataset[dataset['sequence'].apply(lambda x: len(x) < maxlen)]  # Removing sequences with length > 1500\n",
    "    dataset['subsequences'] = sequences2subsequences(dataset.get('sequence'))\n",
    "\n",
    "    if representation == \"matrix\":\n",
    "        matrix = dataset['subsequences'].apply(lambda x: seq2fixed_vec_matrix(x, vocabulary))\n",
    "        dataset['vectors'] = matrix\n",
    "        dataset = dataset[[\"ec_number\", \"vectors\"]]\n",
    "    elif representation == 'vocabulary':\n",
    "        matrix = dataset['subsequences'].apply(lambda x: seq2wordcount_vec(x, vocabulary))\n",
    "        dataset['vectors'] = matrix\n",
    "        dataset = dataset[[\"ec_number\", \"vectors\"]]\n",
    "    elif representation == 'vector':\n",
    "        one_d_vecs = dataset['subsequences'].apply(lambda x: seq2fixed_length_vec(x, vocabulary))\n",
    "        dataset['vectors'] = one_d_vecs\n",
    "        dataset = dataset[[\"ec_number\", \"vectors\"]]\n",
    "    else:\n",
    "        raise ValueError('Insert valid representation: \"vector\", \"matrix\" or \"vocabulary\"')\n",
    "\n",
    "    dataset['ec_number'] = dataset['ec_number'].apply(lambda x: handle_ec_number(x, ecn_level))\n",
    "    dataset = dataset[dataset.get('ec_number').notna()]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffbf34",
   "metadata": {},
   "source": [
    "## Geração do Vocabulário através dos embeddings pre-treinados Protvec\n",
    "\n",
    "Este segmento gera um dicionario de python que a cada trimero presente no Protvec associa o vector correspondente\n",
    "\n",
    "Este dicionário é depois usado na geração de representações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(\"../protVec_100d_3grams.csv\", sep='\\\\t', engine='python', header=None)\n",
    "\n",
    "embeddings[100] = embeddings[100].apply(lambda elem: elem[:-1])\n",
    "threemers = embeddings.get(0)\n",
    "vocab = {}\n",
    "for i, kmer in enumerate(threemers):\n",
    "    vocab[kmer[1:]] = embeddings.iloc[i][1:].to_numpy(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727b910",
   "metadata": {},
   "source": [
    "## Pre-processamento do caso de estudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ecpred_uniprot_uniref_90.csv\")\n",
    "\n",
    "df = parse_dataset(data, vocab, ecn_level=1, representation='matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680270d2",
   "metadata": {},
   "source": [
    "## Informação sobre a distribuição dos labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d321da",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for row in df['ec_number']:\n",
    "    if row not in firstdig:\n",
    "        labels[row] = 1\n",
    "    else:\n",
    "        labels[row] += 1\n",
    "\n",
    "print(labels)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(firstdig.values(), labels=firstdig.keys(), autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7975e",
   "metadata": {},
   "source": [
    "## Serialização dos dados processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df, '../parsed_data/data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
